// BenchmarkService.cs - Dinamik benchmark servisi\n// Bu sınıf uygulama performansını ölçer ve CI/CD pipeline ile entegre çalışır\n\nusing System;\nusing System.Collections.Generic;\nusing System.Diagnostics;\nusing System.IO;\nusing System.Linq;\nusing System.Text.Json;\nusing System.Threading.Tasks;\nusing Microsoft.Extensions.Logging;\n\nnamespace KesifUygulamasiTemplate.Services\n{\n    /// <summary>\n    /// Benchmark sonucu sınıfı\n    /// </summary>\n    public class BenchmarkResult\n    {\n        public string Metric { get; set; }\n        public double Value { get; set; }\n        public string Unit { get; set; }\n        public DateTime Timestamp { get; set; }\n        public string Category { get; set; }\n        public Dictionary<string, object> Metadata { get; set; } = new Dictionary<string, object>();\n        public bool IsBaseline { get; set; }\n        public double? BaselineValue { get; set; }\n        public double? Deviation { get; set; }\n    }\n\n    /// <summary>\n    /// Benchmark istatistikleri\n    /// </summary>\n    public class BenchmarkStatistics\n    {\n        public int TotalBenchmarks { get; set; }\n        public Dictionary<string, int> BenchmarksByCategory { get; set; } = new Dictionary<string, int>();\n        public Dictionary<string, double> AverageValues { get; set; } = new Dictionary<string, double>();\n        public Dictionary<string, double> MinValues { get; set; } = new Dictionary<string, double>();\n        public Dictionary<string, double> MaxValues { get; set; } = new Dictionary<string, double>();\n        public DateTime LastBenchmarkTime { get; set; }\n        public TimeSpan AverageBenchmarkDuration { get; set; }\n    }\n\n    /// <summary>\n    /// Benchmark servisi\n    /// </summary>\n    public class BenchmarkService\n    {\n        private readonly ILogger<BenchmarkService> _logger;\n        private readonly string _benchmarkDataPath;\n        private readonly bool _isTestEnvironment;\n        private readonly List<BenchmarkResult> _results = new List<BenchmarkResult>();\n        private readonly Dictionary<string, double> _baselines = new Dictionary<string, double>();\n\n        // CI/CD için environment variable desteği\n        private readonly bool _autoSaveResults = bool.Parse(Environment.GetEnvironmentVariable("AUTO_SAVE_BENCHMARKS") ?? "true");\n        private readonly int _maxBenchmarkHistory = int.Parse(Environment.GetEnvironmentVariable("MAX_BENCHMARK_HISTORY") ?? "1000");\n        private readonly double _performanceThreshold = double.Parse(Environment.GetEnvironmentVariable("PERFORMANCE_THRESHOLD") ?? "0.1");\n        private readonly string[] _monitoredMetrics = (Environment.GetEnvironmentVariable("MONITORED_METRICS") ?? "route_calculation,map_rendering,tile_loading,api_response").Split(',');\n\n        public event EventHandler<BenchmarkResult> BenchmarkCompleted;\n        public event EventHandler<string> PerformanceAlert;\n\n        public BenchmarkService(ILogger<BenchmarkService> logger)\n        {\n            _logger = logger ?? throw new ArgumentNullException(nameof(logger));\n\n            // Test ortamı kontrolü\n            _isTestEnvironment = Environment.GetEnvironmentVariable("CI") == "true" ||\n                                Environment.GetEnvironmentVariable("TEST_ENVIRONMENT") == "true";\n\n            // Benchmark veri yolu\n            var appDataPath = Environment.GetFolderPath(Environment.SpecialFolder.ApplicationData);\n            _benchmarkDataPath = Path.Combine(appDataPath, "KesifUygulamasi", "BenchmarkData");\n            Directory.CreateDirectory(_benchmarkDataPath);\n\n            _logger.LogInformation("BenchmarkService initialized. Monitored metrics: {Metrics}",\n                string.Join(", ", _monitoredMetrics));\n\n            // Mevcut benchmark verilerini yükle\n            Task.Run(() => LoadBenchmarksAsync()).Wait();\n        }\n\n        /// <summary>\n        /// Benchmark loglar\n        /// </summary>\n        public async Task LogPerformanceAsync(string metric, double value, string unit = "ms", string category = "General")\n        {\n            try\n            {\n                var result = new BenchmarkResult\n                {\n                    Metric = metric,\n                    Value = value,\n                    Unit = unit,\n                    Timestamp = DateTime.UtcNow,\n                    Category = category\n                };\n\n                // Metadata ekleme\n                result.Metadata["environment"] = Environment.GetEnvironmentVariable("ASPNETCORE_ENVIRONMENT") ?? "Production";\n                result.Metadata["platform"] = Environment.GetEnvironmentVariable("PLATFORM") ?? Environment.OSVersion.Platform.ToString();\n                result.Metadata["framework"] = Environment.GetEnvironmentVariable("FRAMEWORK") ?? "Unknown";\n\n                // Baseline karşılaştırma\n                if (_baselines.TryGetValue(metric, out var baseline))\n                {\n                    result.BaselineValue = baseline;\n                    result.Deviation = ((value - baseline) / baseline) * 100;\n                    result.IsBaseline = Math.Abs(result.Deviation.Value) <= _performanceThreshold;\n                }\n\n                _results.Add(result);\n\n                // Performans uyarısı\n                if (result.Deviation.HasValue && Math.Abs(result.Deviation.Value) > _performanceThreshold)\n                {\n                    var alertMessage = $"{metric}: {result.Deviation.Value:F2}% deviation from baseline";\n                    PerformanceAlert?.Invoke(this, alertMessage);\n                    _logger.LogWarning("Performance alert: {Alert}", alertMessage);\n                }\n\n                // Otomatik kaydetme\n                if (_autoSaveResults)\n                {\n                    await SaveBenchmarkAsync(result);\n                }\n\n                // Event tetikleme\n                BenchmarkCompleted?.Invoke(this, result);\n\n                _logger.LogInformation("Benchmark logged: {Metric} = {Value} {Unit} (Category: {Category})",\n                    metric, value, unit, category);\n\n            }\n            catch (Exception ex)\n            {\n                _logger.LogError(ex, "Failed to log benchmark: {Metric}", metric);\n            }\n        }\n\n        /// <summary>\n        /// Senkron benchmark loglama (legacy support)\n        /// </summary>\n        public void LogPerformance(string metric, double value)\n        {\n            Task.Run(() => LogPerformanceAsync(metric, value)).Wait();\n        }\n\n        /// <summary>\n        /// Zamanlayıcı ile benchmark ölçer\n        /// </summary>\n        public async Task<double> MeasureExecutionTimeAsync(string metric, Func<Task> action, string category = "Execution")\n        {\n            var stopwatch = Stopwatch.StartNew();\n\n            try\n            {\n                await action();\n            }\n            finally\n            {\n                stopwatch.Stop();\n                var executionTime = stopwatch.Elapsed.TotalMilliseconds;\n                await LogPerformanceAsync(metric, executionTime, "ms", category);\n            }\n\n            return stopwatch.Elapsed.TotalMilliseconds;\n        }\n\n        /// <summary>\n        /// Senkron zamanlayıcı ile benchmark ölçer\n        /// </summary>\n        public double MeasureExecutionTime(string metric, Action action, string category = "Execution")\n        {\n            var stopwatch = Stopwatch.StartNew();\n\n            try\n            {\n                action();\n            }\n            finally\n            {\n                stopwatch.Stop();\n                var executionTime = stopwatch.Elapsed.TotalMilliseconds;\n                Task.Run(() => LogPerformanceAsync(metric, executionTime, "ms", category)).Wait();\n            }\n\n            return stopwatch.Elapsed.TotalMilliseconds;\n        }\n\n        /// <summary>\n        /// Baseline değerini ayarlar\n        /// </summary>\n        public async Task SetBaselineAsync(string metric, double value)\n        {\n            _baselines[metric] = value;\n\n            // Baseline'ı kaydet\n            await SaveBaselinesAsync();\n\n            _logger.LogInformation("Baseline set for {Metric}: {Value}", metric, value);\n        }\n\n        /// <summary>\n        /// Benchmark istatistiklerini döndürür\n        /// </summary>\n        public async Task<BenchmarkStatistics> GetBenchmarkStatisticsAsync()\n        {\n            await LoadBenchmarksAsync(); // En güncel veriyi yükle\n\n            var stats = new BenchmarkStatistics\n            {\n                TotalBenchmarks = _results.Count,\n                LastBenchmarkTime = _results.Any() ? _results.Max(r => r.Timestamp) : DateTime.MinValue\n            };\n\n            if (_results.Any())\n            {\n                // Kategori bazlı istatistikler\n                var categoryGroups = _results.GroupBy(r => r.Category);\n                foreach (var group in categoryGroups)\n                {\n                    stats.BenchmarksByCategory[group.Key] = group.Count();\n                }\n\n                // Metrik bazlı istatistikler\n                var metricGroups = _results.GroupBy(r => r.Metric);\n                foreach (var group in metricGroups)\n                {\n                    stats.AverageValues[group.Key] = group.Average(r => r.Value);\n                    stats.MinValues[group.Key] = group.Min(r => r.Value);\n                    stats.MaxValues[group.Key] = group.Max(r => r.Value);\n                }\n\n                // Ortalama benchmark süresi hesaplama\n                var benchmarkDurations = _results.GroupBy(r => r.Timestamp.Date)\n                    .Select(g => g.Count())\n                    .ToList();\n\n                if (benchmarkDurations.Any())\n                {\n                    stats.AverageBenchmarkDuration = TimeSpan.FromMinutes(benchmarkDurations.Average());\n                }\n            }\n\n            return stats;\n        }\n\n        /// <summary>\n        /// Metriğe göre benchmark sonuçlarını filtreler\n        /// </summary>\n        public async Task<IEnumerable<BenchmarkResult>> GetBenchmarksByMetricAsync(string metric)\n        {\n            await LoadBenchmarksAsync();\n            return _results.Where(r => r.Metric.Equals(metric, StringComparison.OrdinalIgnoreCase));\n        }\n\n        /// <summary>\n        /// Kategoriye göre benchmark sonuçlarını filtreler\n        /// </summary>\n        public async Task<IEnumerable<BenchmarkResult>> GetBenchmarksByCategoryAsync(string category)\n        {\n            await LoadBenchmarksAsync();\n            return _results.Where(r => r.Category.Equals(category, StringComparison.OrdinalIgnoreCase));\n        }\n\n        /// <summary>\n        /// Zaman aralığına göre benchmark sonuçlarını filtreler\n        /// </summary>\n        public async Task<IEnumerable<BenchmarkResult>> GetBenchmarksByTimeRangeAsync(DateTime startTime, DateTime endTime)\n        {\n            await LoadBenchmarksAsync();\n            return _results.Where(r => r.Timestamp >= startTime && r.Timestamp <= endTime);\n        }\n\n        /// <summary>\n        /// Performans regresyonunu kontrol eder\n        /// </summary>\n        public async Task<bool> CheckPerformanceRegressionAsync(string metric, double threshold = 0.1)\n        {\n            var recentResults = await GetBenchmarksByMetricAsync(metric);\n            var recentResultsList = recentResults.OrderByDescending(r => r.Timestamp).Take(10).ToList();\n\n            if (recentResultsList.Count < 2)\n                return false;\n\n            var latest = recentResultsList.First();\n            var previous = recentResultsList.Skip(1).Take(5).Average(r => r.Value);\n\n            var regression = ((latest.Value - previous) / previous) * 100;\n\n            if (Math.Abs(regression) > threshold * 100)\n            {\n                _logger.LogWarning("Performance regression detected for {Metric}: {Regression:F2}%", metric, regression);\n                return true;\n            }\n\n            return false;\n        }\n\n        /// <summary>\n        /// Benchmark verilerini dosyaya kaydeder\n        /// </summary>\n        private async Task SaveBenchmarkAsync(BenchmarkResult result)\n        {\n            try\n            {\n                var fileName = $"benchmark_{DateTime.UtcNow:yyyyMMdd_HHmmss}.json";\n                var filePath = Path.Combine(_benchmarkDataPath, fileName);\n\n                var json = JsonSerializer.Serialize(result, new JsonSerializerOptions\n                {\n                    WriteIndented = true,\n                    PropertyNamingPolicy = JsonNamingPolicy.CamelCase\n                });\n\n                await File.WriteAllTextAsync(filePath, json);\n                _logger.LogInformation("Benchmark saved to {FilePath}", filePath);\n            }\n            catch (Exception ex)\n            {\n                _logger.LogError(ex, "Failed to save benchmark");\n                throw;\n            }\n        }\n\n        /// <summary>\n        /// Baseline değerlerini kaydeder\n        /// </summary>\n        private async Task SaveBaselinesAsync()\n        {\n            try\n            {\n                var baselinePath = Path.Combine(_benchmarkDataPath, "baselines.json");\n                var json = JsonSerializer.Serialize(_baselines, new JsonSerializerOptions { WriteIndented = true });\n                await File.WriteAllTextAsync(baselinePath, json);\n                _logger.LogInformation("Baselines saved");\n            }\n            catch (Exception ex)\n            {\n                _logger.LogError(ex, "Failed to save baselines");\n            }\n        }\n\n        /// <summary>\n        /// Benchmark verilerini dosyadan yükler\n        /// </summary>\n        private async Task LoadBenchmarksAsync()\n        {\n            try\n            {\n                var benchmarkFiles = Directory.GetFiles(_benchmarkDataPath, "benchmark_*.json")\n                    .OrderByDescending(f => f)\n                    .Take(_maxBenchmarkHistory);\n\n                _results.Clear();\n\n                foreach (var file in benchmarkFiles)\n                {\n                    try\n                    {\n                        var json = await File.ReadAllTextAsync(file);\n                        var result = JsonSerializer.Deserialize<BenchmarkResult>(json);\n                        if (result != null)\n                        {\n                            _results.Add(result);\n                        }\n                    }\n                    catch (Exception ex)\n                    {\n                        _logger.LogWarning(ex, "Failed to load benchmark from {File}", file);\n                    }\n                }\n\n                // Baseline'ları yükle\n                var baselinePath = Path.Combine(_benchmarkDataPath, "baselines.json");\n                if (File.Exists(baselinePath))\n                {\n                    var baselineJson = await File.ReadAllTextAsync(baselinePath);\n                    var baselines = JsonSerializer.Deserialize<Dictionary<string, double>>(baselineJson);\n                    if (baselines != null)\n                    {\n                        _baselines.Clear();\n                        foreach (var kvp in baselines)\n                        {\n                            _baselines[kvp.Key] = kvp.Value;\n                        }\n                    }\n                }\n\n                _logger.LogInformation("Loaded {Count} benchmarks and {BaselineCount} baselines",\n                    _results.Count, _baselines.Count);\n            }\n            catch (Exception ex)\n            {\n                _logger.LogError(ex, "Failed to load benchmarks");\n            }\n        }\n\n        /// <summary>\n        /// Örnek benchmark'lar oluşturur (test için)\n        /// </summary>\n        public async Task CreateSampleBenchmarksAsync()\n        {\n            if (!_isTestEnvironment)\n                return;\n\n            var sampleBenchmarks = new[]\n            {\n                new { Metric = "route_calculation", Value = 150.5, Unit = "ms", Category = "Navigation" },\n                new { Metric = "map_rendering", Value = 45.2, Unit = "ms", Category = "UI" },\n                new { Metric = "tile_loading", Value = 120.8, Unit = "ms", Category = "Data" },\n                new { Metric = "api_response", Value = 200.3, Unit = "ms", Category = "Network" },\n                new { Metric = "database_query", Value = 25.7, Unit = "ms", Category = "Data" },\n                new { Metric = "image_processing", Value = 89.4, Unit = "ms", Category = "Media" }\n            };\n\n            foreach (var sample in sampleBenchmarks)\n            {\n                await LogPerformanceAsync(sample.Metric, sample.Value, sample.Unit, sample.Category);\n            }\n\n            _logger.LogInformation("Sample benchmarks created for testing");\n        }\n\n        /// <summary>\n        /// Benchmark geçmişini temizler\n        /// </summary>\n        public async Task ClearBenchmarkHistoryAsync()\n        {\n            if (!_isTestEnvironment)\n            {\n                _logger.LogWarning("Benchmark history clearing only allowed in test environment");\n                return;\n            }\n\n            try\n            {\n                var benchmarkFiles = Directory.GetFiles(_benchmarkDataPath, "benchmark_*.json");\n                foreach (var file in benchmarkFiles)\n                {\n                    File.Delete(file);\n                }\n\n                _results.Clear();\n                _logger.LogInformation("Benchmark history cleared");\n            }\n            catch (Exception ex)\n            {\n                _logger.LogError(ex, "Failed to clear benchmark history");\n            }\n        }\n    }\n}\n